From c2686a327a2d48ed15ff4150dd86fb97a37aecae Mon Sep 17 00:00:00 2001
From: Aleksei Sidorov <>
Date: Wed, 1 Jun 2022 19:45:36 +0300
Subject: [PATCH 3/4] Miscellaneous fixes

---
 src/aarch32/instructions-aarch32.h     |  27 ++-
 src/aarch32/location-aarch32.h         |   3 +-
 src/aarch32/macro-assembler-aarch32.h  |  50 +++-
 src/aarch64/assembler-aarch64.h        |   1 +
 src/aarch64/logic-aarch64.cc           |   3 +
 src/aarch64/macro-assembler-aarch64.cc |   2 +
 src/aarch64/macro-assembler-aarch64.h  |   5 +
 src/aarch64/operands-aarch64.cc        |  36 ++-
 src/aarch64/operands-aarch64.h         |  24 +-
 src/aarch64/registers-aarch64.cc       | 321 -------------------------
 src/aarch64/registers-aarch64.h        | 313 +++++++++++++++++++++---
 src/assembler-base-vixl.h              |  12 +-
 src/code-buffer-vixl.cc                |   7 +
 src/code-generation-scopes-vixl.h      |   2 +-
 src/pool-manager.h                     |   4 +
 15 files changed, 396 insertions(+), 414 deletions(-)
 delete mode 100644 src/aarch64/registers-aarch64.cc

diff --git a/src/aarch32/instructions-aarch32.h b/src/aarch32/instructions-aarch32.h
index e2c95d19..8543a07d 100644
--- a/src/aarch32/instructions-aarch32.h
+++ b/src/aarch32/instructions-aarch32.h
@@ -38,8 +38,8 @@ extern "C" {
 #include "utils-vixl.h"
 #include "aarch32/constants-aarch32.h"
 
-#if defined(__arm__) && !defined(__SOFTFP__)
-#define HARDFLOAT __attribute__((noinline, pcs("aapcs-vfp")))
+#if !defined(__linux__) && defined(__arm__)
+#define HARDFLOAT gnu__attribute__((noinline, pcs("aapcs-vfp")))
 #else
 #define HARDFLOAT __attribute__((noinline))
 #endif
@@ -79,7 +79,7 @@ class CPURegister {
   uint32_t value_;
 
  public:
-  CPURegister(RegisterType type, uint32_t code, int size)
+  constexpr CPURegister(RegisterType type, uint32_t code, int size)
       : value_((type << kTypeShift) | (code << kCodeShift) |
                (size << kSizeShift)) {
 #ifdef VIXL_DEBUG
@@ -108,7 +108,7 @@ class CPURegister {
     }
 #endif
   }
-  RegisterType GetType() const {
+  constexpr RegisterType GetType() const {
     return static_cast<RegisterType>((value_ & kTypeMask) >> kTypeShift);
   }
   bool IsRegister() const { return GetType() == kRRegister; }
@@ -134,8 +134,8 @@ class CPURegister {
 
 class Register : public CPURegister {
  public:
-  Register() : CPURegister(kNoRegister, 0, kRegSizeInBits) {}
-  explicit Register(uint32_t code)
+  constexpr Register() : CPURegister(kNoRegister, 0, kRegSizeInBits) {}
+  explicit constexpr  Register(uint32_t code)
       : CPURegister(kRRegister, code % kNumberOfRegisters, kRegSizeInBits) {
     VIXL_ASSERT(GetCode() < kNumberOfRegisters);
   }
@@ -457,19 +457,19 @@ const QRegister NoQReg;
 
 class RegisterList {
  public:
-  RegisterList() : list_(0) {}
-  RegisterList(Register reg)  // NOLINT(runtime/explicit)
+  constexpr RegisterList() : list_(0) {}
+  constexpr RegisterList(Register reg)  // NOLINT(runtime/explicit)
       : list_(RegisterToList(reg)) {}
-  RegisterList(Register reg1, Register reg2)
+  constexpr RegisterList(Register reg1, Register reg2)
       : list_(RegisterToList(reg1) | RegisterToList(reg2)) {}
-  RegisterList(Register reg1, Register reg2, Register reg3)
+  constexpr RegisterList(Register reg1, Register reg2, Register reg3)
       : list_(RegisterToList(reg1) | RegisterToList(reg2) |
               RegisterToList(reg3)) {}
-  RegisterList(Register reg1, Register reg2, Register reg3, Register reg4)
+  constexpr RegisterList(Register reg1, Register reg2, Register reg3, Register reg4)
       : list_(RegisterToList(reg1) | RegisterToList(reg2) |
               RegisterToList(reg3) | RegisterToList(reg4)) {}
   explicit RegisterList(uint32_t list) : list_(list) {}
-  uint32_t GetList() const { return list_; }
+  constexpr uint32_t GetList() const { return list_; }
   void SetList(uint32_t list) { list_ = list; }
   bool Includes(const Register& reg) const {
     return (list_ & RegisterToList(reg)) != 0;
@@ -526,7 +526,7 @@ class RegisterList {
   }
 
  private:
-  static uint32_t RegisterToList(Register reg) {
+  static constexpr uint32_t RegisterToList(Register reg) {
     if (reg.GetType() == CPURegister::kNoRegister) {
       return 0;
     } else {
@@ -561,6 +561,7 @@ class VRegisterList {
               RegisterToList(reg3) | RegisterToList(reg4)) {}
   explicit VRegisterList(uint64_t list) : list_(list) {}
   uint64_t GetList() const { return list_; }
+  int GetCount() const { return CountSetBits(list_); }
   void SetList(uint64_t list) { list_ = list; }
   // Because differently-sized V registers overlap with one another, there is no
   // way to implement a single 'Includes' function in a way that is unsurprising
diff --git a/src/aarch32/location-aarch32.h b/src/aarch32/location-aarch32.h
index 7da979c5..14da0d7a 100644
--- a/src/aarch32/location-aarch32.h
+++ b/src/aarch32/location-aarch32.h
@@ -72,7 +72,8 @@ class Location : public LocationBase<int32_t> {
   typedef int32_t Offset;
 
   ~Location() VIXL_NEGATIVE_TESTING_ALLOW_EXCEPTION {
-#ifdef VIXL_DEBUG
+    // Codegen may create empty labels
+#if defined(VIXL_DEBUG) && !defined(PANDA_BUILD)
     if (IsReferenced() && !IsBound()) {
       VIXL_ABORT_WITH_MSG("Location, label or literal used but not bound.\n");
     }
diff --git a/src/aarch32/macro-assembler-aarch32.h b/src/aarch32/macro-assembler-aarch32.h
index ceaf7557..54d386dd 100644
--- a/src/aarch32/macro-assembler-aarch32.h
+++ b/src/aarch32/macro-assembler-aarch32.h
@@ -541,60 +541,90 @@ ITScope(panda::ArenaAllocator* allocator, MacroAssembler* masm,
     GetBuffer()->EnsureSpaceFor(size);
   }
 
-  bool AliasesAvailableScratchRegister(Register reg) {
+  bool AliasesAvailableScratchRegister([[maybe_unused]] Register reg) {
+#ifndef PANDA_BUILD
     return GetScratchRegisterList()->Includes(reg);
+#endif
+    return false;
   }
 
-  bool AliasesAvailableScratchRegister(RegisterOrAPSR_nzcv reg) {
+  bool AliasesAvailableScratchRegister([[maybe_unused]] RegisterOrAPSR_nzcv reg) {
+#ifndef PANDA_BUILD
     if (reg.IsAPSR_nzcv()) return false;
     return GetScratchRegisterList()->Includes(reg.AsRegister());
+#endif
+    return false;
   }
 
-  bool AliasesAvailableScratchRegister(VRegister reg) {
+  bool AliasesAvailableScratchRegister([[maybe_unused]] VRegister reg) {
+#ifndef PANDA_BUILD
     return GetScratchVRegisterList()->IncludesAliasOf(reg);
+#endif
+    return false;
   }
 
-  bool AliasesAvailableScratchRegister(const Operand& operand) {
+  bool AliasesAvailableScratchRegister([[maybe_unused]] const Operand& operand) {
+#ifndef PANDA_BUILD
     if (operand.IsImmediate()) return false;
     return AliasesAvailableScratchRegister(operand.GetBaseRegister()) ||
            (operand.IsRegisterShiftedRegister() &&
             AliasesAvailableScratchRegister(operand.GetShiftRegister()));
+#endif
+    return false;
   }
 
-  bool AliasesAvailableScratchRegister(const NeonOperand& operand) {
+  bool AliasesAvailableScratchRegister([[maybe_unused]] const NeonOperand& operand) {
+#ifndef PANDA_BUILD
     if (operand.IsImmediate()) return false;
     return AliasesAvailableScratchRegister(operand.GetRegister());
+#endif
+    return false;
   }
 
-  bool AliasesAvailableScratchRegister(SRegisterList list) {
+  bool AliasesAvailableScratchRegister([[maybe_unused]] SRegisterList list) {
+#ifndef PANDA_BUILD
     for (int n = 0; n < list.GetLength(); n++) {
       if (AliasesAvailableScratchRegister(list.GetSRegister(n))) return true;
     }
     return false;
+#endif
+    return false;
   }
 
-  bool AliasesAvailableScratchRegister(DRegisterList list) {
+  bool AliasesAvailableScratchRegister([[maybe_unused]] DRegisterList list) {
+#ifndef PANDA_BUILD
     for (int n = 0; n < list.GetLength(); n++) {
       if (AliasesAvailableScratchRegister(list.GetDRegister(n))) return true;
     }
     return false;
+#endif
+    return false;
   }
 
-  bool AliasesAvailableScratchRegister(NeonRegisterList list) {
+  bool AliasesAvailableScratchRegister([[maybe_unused]] NeonRegisterList list) {
+#ifndef PANDA_BUILD
     for (int n = 0; n < list.GetLength(); n++) {
       if (AliasesAvailableScratchRegister(list.GetDRegister(n))) return true;
     }
     return false;
+#endif
+    return false;
   }
 
-  bool AliasesAvailableScratchRegister(RegisterList list) {
+  bool AliasesAvailableScratchRegister([[maybe_unused]] RegisterList list) {
+#ifndef PANDA_BUILD
     return GetScratchRegisterList()->Overlaps(list);
+#endif
+    return false;
   }
 
-  bool AliasesAvailableScratchRegister(const MemOperand& operand) {
+  bool AliasesAvailableScratchRegister([[maybe_unused]] const MemOperand& operand) {
+#ifndef PANDA_BUILD
     return AliasesAvailableScratchRegister(operand.GetBaseRegister()) ||
            (operand.IsShiftedRegister() &&
             AliasesAvailableScratchRegister(operand.GetOffsetRegister()));
+#endif
+    return false;
   }
 
   // Adr with a literal already constructed. Add the literal to the pool if it
diff --git a/src/aarch64/assembler-aarch64.h b/src/aarch64/assembler-aarch64.h
index c8135974..91e50ed7 100644
--- a/src/aarch64/assembler-aarch64.h
+++ b/src/aarch64/assembler-aarch64.h
@@ -852,6 +852,7 @@ class Assembler : public vixl::internal::AssemblerBase {
   void lsl(const Register& rd, const Register& rn, unsigned shift) {
     unsigned reg_size = rd.GetSizeInBits();
     VIXL_ASSERT(shift < reg_size);
+    // NOLINTNEXTLINE(clang-analyzer-core.DivideZero)
     ubfm(rd, rn, (reg_size - shift) % reg_size, reg_size - shift - 1);
   }
 
diff --git a/src/aarch64/logic-aarch64.cc b/src/aarch64/logic-aarch64.cc
index a77e7f28..f9250ea8 100644
--- a/src/aarch64/logic-aarch64.cc
+++ b/src/aarch64/logic-aarch64.cc
@@ -4565,6 +4565,9 @@ T Simulator::FPMulAdd(T a, T op1, T op2) {
   return result;
 }
 
+template float Simulator::FPMulAdd(float a, float op1, float op2);
+
+template double Simulator::FPMulAdd(double a, double op1, double op2);
 
 template <typename T>
 T Simulator::FPDiv(T op1, T op2) {
diff --git a/src/aarch64/macro-assembler-aarch64.cc b/src/aarch64/macro-assembler-aarch64.cc
index 687fd0b7..0bc8268b 100644
--- a/src/aarch64/macro-assembler-aarch64.cc
+++ b/src/aarch64/macro-assembler-aarch64.cc
@@ -2489,7 +2489,9 @@ void MacroAssembler::LoadStoreCPURegListHelper(LoadStoreCPURegListAction op,
                                                const MemOperand& mem) {
   // We do not handle pre-indexing or post-indexing.
   VIXL_ASSERT(!(mem.IsPreIndex() || mem.IsPostIndex()));
+#ifndef PANDA_BUILD
   VIXL_ASSERT(!registers.Overlaps(tmp_list_));
+#endif
   VIXL_ASSERT(!registers.Overlaps(v_tmp_list_));
   VIXL_ASSERT(!registers.Overlaps(p_tmp_list_));
   VIXL_ASSERT(!registers.IncludesAliasOf(sp));
diff --git a/src/aarch64/macro-assembler-aarch64.h b/src/aarch64/macro-assembler-aarch64.h
index 2f77358e..8ec087e2 100644
--- a/src/aarch64/macro-assembler-aarch64.h
+++ b/src/aarch64/macro-assembler-aarch64.h
@@ -1217,6 +1217,11 @@ MacroAssembler(panda::ArenaAllocator* allocator, byte* buffer,
     SingleEmissionCheckScope guard(this);
     bl(label);
   }
+  void Bl(int64_t offset) {
+    VIXL_ASSERT(allow_macro_instructions_);
+    SingleEmissionCheckScope guard(this);
+    bl(offset >> kInstructionSizeLog2);
+  }
   void Blr(const Register& xn) {
     VIXL_ASSERT(allow_macro_instructions_);
     VIXL_ASSERT(!xn.IsZero());
diff --git a/src/aarch64/operands-aarch64.cc b/src/aarch64/operands-aarch64.cc
index 8db129c9..a00e3908 100644
--- a/src/aarch64/operands-aarch64.cc
+++ b/src/aarch64/operands-aarch64.cc
@@ -112,38 +112,29 @@ CPURegList CPURegList::Intersection(const CPURegList& list_1,
 }
 
 
-CPURegList CPURegList::GetCalleeSaved(unsigned size) {
-  return CPURegList(CPURegister::kRegister, size, 19, 29);
+CPURegList CPURegList::GetCalleeSaved([[maybe_unused]] unsigned size) {
+  VIXL_ASSERT(size == static_cast<unsigned>(kCalleeSaved.GetRegisterSizeInBits()));
+  return kCalleeSaved;
 }
 
 
-CPURegList CPURegList::GetCalleeSavedV(unsigned size) {
-  return CPURegList(CPURegister::kVRegister, size, 8, 15);
+CPURegList CPURegList::GetCalleeSavedV([[maybe_unused]] unsigned size) {
+  VIXL_ASSERT(size == static_cast<unsigned>(kCalleeSavedV.GetRegisterSizeInBits()));
+  return kCalleeSavedV;
 }
 
 
-CPURegList CPURegList::GetCallerSaved(unsigned size) {
-  // Registers x0-x18 and lr (x30) are caller-saved.
-  CPURegList list = CPURegList(CPURegister::kRegister, size, 0, 18);
-  // Do not use lr directly to avoid initialisation order fiasco bugs for users.
-  list.Combine(Register(30, kXRegSize));
-  return list;
+CPURegList CPURegList::GetCallerSaved([[maybe_unused]] unsigned size) {
+  VIXL_ASSERT(size == static_cast<unsigned>(kCallerSaved.GetRegisterSizeInBits()));
+  return kCallerSaved;
 }
 
 
-CPURegList CPURegList::GetCallerSavedV(unsigned size) {
-  // Registers d0-d7 and d16-d31 are caller-saved.
-  CPURegList list = CPURegList(CPURegister::kVRegister, size, 0, 7);
-  list.Combine(CPURegList(CPURegister::kVRegister, size, 16, 31));
-  return list;
+CPURegList CPURegList::GetCallerSavedV([[maybe_unused]] unsigned size) {
+  VIXL_ASSERT(size == static_cast<unsigned>(kCallerSavedV.GetRegisterSizeInBits()));
+  return kCallerSavedV;
 }
 
-
-const CPURegList kCalleeSaved = CPURegList::GetCalleeSaved();
-const CPURegList kCalleeSavedV = CPURegList::GetCalleeSavedV();
-const CPURegList kCallerSaved = CPURegList::GetCallerSaved();
-const CPURegList kCallerSavedV = CPURegList::GetCallerSavedV();
-
 // Operand.
 Operand::Operand(int64_t immediate)
     : immediate_(immediate),
@@ -238,7 +229,8 @@ MemOperand::MemOperand()
       offset_(0),
       addrmode_(Offset),
       shift_(NO_SHIFT),
-      extend_(NO_EXTEND) {}
+      extend_(NO_EXTEND),
+      shift_amount_(0) {}
 
 
 MemOperand::MemOperand(Register base, int64_t offset, AddrMode addrmode)
diff --git a/src/aarch64/operands-aarch64.h b/src/aarch64/operands-aarch64.h
index 08ee4a61..e8374d62 100644
--- a/src/aarch64/operands-aarch64.h
+++ b/src/aarch64/operands-aarch64.h
@@ -50,24 +50,27 @@ class CPURegList {
     VIXL_ASSERT(IsValid());
   }
 
-  CPURegList(CPURegister::RegisterType type, unsigned size, RegList list)
+  constexpr CPURegList(CPURegister::RegisterType type, unsigned size, RegList list)
       : list_(list), size_(size), type_(type) {
+#ifndef PANDA_BUILD
     VIXL_ASSERT(IsValid());
+#endif
   }
 
-  CPURegList(CPURegister::RegisterType type,
+  constexpr CPURegList(CPURegister::RegisterType type,
              unsigned size,
              unsigned first_reg,
              unsigned last_reg)
-      : size_(size), type_(type) {
+      : list_((UINT64_C(1) << (last_reg + 1)) - 1), size_(size), type_(type) {
     VIXL_ASSERT(
         ((type == CPURegister::kRegister) && (last_reg < kNumberOfRegisters)) ||
         ((type == CPURegister::kVRegister) &&
          (last_reg < kNumberOfVRegisters)));
     VIXL_ASSERT(last_reg >= first_reg);
-    list_ = (UINT64_C(1) << (last_reg + 1)) - 1;
     list_ &= ~((UINT64_C(1) << first_reg) - 1);
+#ifndef PANDA_BUILD
     VIXL_ASSERT(IsValid());
+#endif
   }
 
   // Construct an empty CPURegList with the specified size and type. If `size`
@@ -182,8 +185,10 @@ class CPURegList {
     return (type_ == other.type_) && ((list_ & other.list_) != 0);
   }
 
-  RegList GetList() const {
+  constexpr RegList GetList() const {
+#ifndef PANDA_BUILD
     VIXL_ASSERT(IsValid());
+#endif
     return list_;
   }
   VIXL_DEPRECATED("GetList", RegList list() const) { return GetList(); }
@@ -287,13 +292,12 @@ class CPURegList {
 
 
 // AAPCS64 callee-saved registers.
-extern const CPURegList kCalleeSaved;
-extern const CPURegList kCalleeSavedV;
-
+constexpr CPURegList kCalleeSaved = CPURegList(CPURegister::kRegister, kXRegSize, 19, 28);
+constexpr CPURegList kCalleeSavedV = CPURegList(CPURegister::kVRegister, kDRegSize, 8, 15);
 
 // AAPCS64 caller-saved registers. Note that this includes lr.
-extern const CPURegList kCallerSaved;
-extern const CPURegList kCallerSavedV;
+constexpr CPURegList kCallerSaved = CPURegList(CPURegister::kRegister, kXRegSize, 0, 18);
+constexpr CPURegList kCallerSavedV = CPURegList(CPURegister::kVRegister, kDRegSize, 0xffff00ff);
 
 class IntegerOperand;
 
diff --git a/src/aarch64/registers-aarch64.cc b/src/aarch64/registers-aarch64.cc
deleted file mode 100644
index 735f43c7..00000000
--- a/src/aarch64/registers-aarch64.cc
+++ /dev/null
@@ -1,321 +0,0 @@
-// Copyright 2019, VIXL authors
-// All rights reserved.
-//
-// Redistribution and use in source and binary forms, with or without
-// modification, are permitted provided that the following conditions are met:
-//
-//   * Redistributions of source code must retain the above copyright notice,
-//     this list of conditions and the following disclaimer.
-//   * Redistributions in binary form must reproduce the above copyright notice,
-//     this list of conditions and the following disclaimer in the documentation
-//     and/or other materials provided with the distribution.
-//   * Neither the name of ARM Limited nor the names of its contributors may be
-//     used to endorse or promote products derived from this software without
-//     specific prior written permission.
-//
-// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS CONTRIBUTORS "AS IS" AND
-// ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
-// WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-// DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE
-// FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
-// DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
-// SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
-// CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
-// OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-#include <sstream>
-#include <string>
-
-#include "registers-aarch64.h"
-
-namespace vixl {
-namespace aarch64 {
-
-std::string CPURegister::GetArchitecturalName() const {
-  std::ostringstream name;
-  if (IsZRegister()) {
-    name << 'z' << GetCode();
-    if (HasLaneSize()) {
-      name << '.' << GetLaneSizeSymbol();
-    }
-  } else if (IsPRegister()) {
-    name << 'p' << GetCode();
-    if (HasLaneSize()) {
-      name << '.' << GetLaneSizeSymbol();
-    }
-    switch (qualifiers_) {
-      case kNoQualifiers:
-        break;
-      case kMerging:
-        name << "/m";
-        break;
-      case kZeroing:
-        name << "/z";
-        break;
-    }
-  } else {
-    VIXL_UNIMPLEMENTED();
-  }
-  return name.str();
-}
-
-unsigned CPURegister::GetMaxCodeFor(CPURegister::RegisterBank bank) {
-  switch (bank) {
-    case kNoRegisterBank:
-      return 0;
-    case kRRegisterBank:
-      return Register::GetMaxCode();
-    case kVRegisterBank:
-#ifdef VIXL_HAS_CONSTEXPR
-      VIXL_STATIC_ASSERT(VRegister::GetMaxCode() == ZRegister::GetMaxCode());
-#else
-      VIXL_ASSERT(VRegister::GetMaxCode() == ZRegister::GetMaxCode());
-#endif
-      return VRegister::GetMaxCode();
-    case kPRegisterBank:
-      return PRegister::GetMaxCode();
-  }
-  VIXL_UNREACHABLE();
-  return 0;
-}
-
-bool CPURegister::IsValidRegister() const {
-  return ((code_ < kNumberOfRegisters) || (code_ == kSPRegInternalCode)) &&
-         (bank_ == kRRegisterBank) &&
-         ((size_ == kEncodedWRegSize) || (size_ == kEncodedXRegSize)) &&
-         (qualifiers_ == kNoQualifiers) && (lane_size_ == size_);
-}
-
-bool CPURegister::IsValidVRegister() const {
-  VIXL_STATIC_ASSERT(kEncodedBRegSize < kEncodedQRegSize);
-  return (code_ < kNumberOfVRegisters) && (bank_ == kVRegisterBank) &&
-         ((size_ >= kEncodedBRegSize) && (size_ <= kEncodedQRegSize)) &&
-         (qualifiers_ == kNoQualifiers) &&
-         (lane_size_ != kEncodedUnknownSize) && (lane_size_ <= size_);
-}
-
-bool CPURegister::IsValidFPRegister() const {
-  return IsValidVRegister() && IsFPRegister();
-}
-
-bool CPURegister::IsValidZRegister() const {
-  VIXL_STATIC_ASSERT(kEncodedBRegSize < kEncodedQRegSize);
-  // Z registers are valid with or without a lane size, so we don't need to
-  // check lane_size_.
-  return (code_ < kNumberOfZRegisters) && (bank_ == kVRegisterBank) &&
-         (size_ == kEncodedUnknownSize) && (qualifiers_ == kNoQualifiers);
-}
-
-bool CPURegister::IsValidPRegister() const {
-  VIXL_STATIC_ASSERT(kEncodedBRegSize < kEncodedQRegSize);
-  // P registers are valid with or without a lane size, so we don't need to
-  // check lane_size_.
-  return (code_ < kNumberOfPRegisters) && (bank_ == kPRegisterBank) &&
-         (size_ == kEncodedUnknownSize) &&
-         ((qualifiers_ == kNoQualifiers) || (qualifiers_ == kMerging) ||
-          (qualifiers_ == kZeroing));
-}
-
-bool CPURegister::IsValid() const {
-  return IsValidRegister() || IsValidVRegister() || IsValidZRegister() ||
-         IsValidPRegister();
-}
-
-// Most coersions simply invoke the necessary constructor.
-#define VIXL_CPUREG_COERCION_LIST(U) \
-  U(Register, W, R)                  \
-  U(Register, X, R)                  \
-  U(VRegister, B, V)                 \
-  U(VRegister, H, V)                 \
-  U(VRegister, S, V)                 \
-  U(VRegister, D, V)                 \
-  U(VRegister, Q, V)                 \
-  U(VRegister, V, V)                 \
-  U(ZRegister, Z, V)                 \
-  U(PRegister, P, P)
-#define VIXL_DEFINE_CPUREG_COERCION(RET_TYPE, CTOR_TYPE, BANK) \
-  RET_TYPE CPURegister::CTOR_TYPE() const {                    \
-    VIXL_ASSERT(GetBank() == k##BANK##RegisterBank);           \
-    return CTOR_TYPE##Register(GetCode());                     \
-  }
-VIXL_CPUREG_COERCION_LIST(VIXL_DEFINE_CPUREG_COERCION)
-#undef VIXL_CPUREG_COERCION_LIST
-#undef VIXL_DEFINE_CPUREG_COERCION
-
-// NEON lane-format coersions always return VRegisters.
-#define VIXL_CPUREG_NEON_COERCION_LIST(V) \
-  V(8, B)                                 \
-  V(16, B)                                \
-  V(2, H)                                 \
-  V(4, H)                                 \
-  V(8, H)                                 \
-  V(2, S)                                 \
-  V(4, S)                                 \
-  V(1, D)                                 \
-  V(2, D)
-#define VIXL_DEFINE_CPUREG_NEON_COERCION(LANES, LANE_TYPE)             \
-  VRegister VRegister::V##LANES##LANE_TYPE() const {                   \
-    VIXL_ASSERT(IsVRegister());                                        \
-    return VRegister(GetCode(), LANES * k##LANE_TYPE##RegSize, LANES); \
-  }
-VIXL_CPUREG_NEON_COERCION_LIST(VIXL_DEFINE_CPUREG_NEON_COERCION)
-#undef VIXL_CPUREG_NEON_COERCION_LIST
-#undef VIXL_DEFINE_CPUREG_NEON_COERCION
-
-// Semantic type coersion for sdot and udot.
-// TODO: Use the qualifiers_ field to distinguish this from ::S().
-VRegister VRegister::S4B() const {
-  VIXL_ASSERT(IsVRegister());
-  return SRegister(GetCode());
-}
-
-bool AreAliased(const CPURegister& reg1,
-                const CPURegister& reg2,
-                const CPURegister& reg3,
-                const CPURegister& reg4,
-                const CPURegister& reg5,
-                const CPURegister& reg6,
-                const CPURegister& reg7,
-                const CPURegister& reg8) {
-  int number_of_valid_regs = 0;
-  int number_of_valid_vregs = 0;
-  int number_of_valid_pregs = 0;
-
-  RegList unique_regs = 0;
-  RegList unique_vregs = 0;
-  RegList unique_pregs = 0;
-
-  const CPURegister regs[] = {reg1, reg2, reg3, reg4, reg5, reg6, reg7, reg8};
-
-  for (size_t i = 0; i < ArrayLength(regs); i++) {
-    switch (regs[i].GetBank()) {
-      case CPURegister::kRRegisterBank:
-        number_of_valid_regs++;
-        unique_regs |= regs[i].GetBit();
-        break;
-      case CPURegister::kVRegisterBank:
-        number_of_valid_vregs++;
-        unique_vregs |= regs[i].GetBit();
-        break;
-      case CPURegister::kPRegisterBank:
-        number_of_valid_pregs++;
-        unique_pregs |= regs[i].GetBit();
-        break;
-      case CPURegister::kNoRegisterBank:
-        VIXL_ASSERT(regs[i].IsNone());
-        break;
-    }
-  }
-
-  int number_of_unique_regs = CountSetBits(unique_regs);
-  int number_of_unique_vregs = CountSetBits(unique_vregs);
-  int number_of_unique_pregs = CountSetBits(unique_pregs);
-
-  VIXL_ASSERT(number_of_valid_regs >= number_of_unique_regs);
-  VIXL_ASSERT(number_of_valid_vregs >= number_of_unique_vregs);
-  VIXL_ASSERT(number_of_valid_pregs >= number_of_unique_pregs);
-
-  return (number_of_valid_regs != number_of_unique_regs) ||
-         (number_of_valid_vregs != number_of_unique_vregs) ||
-         (number_of_valid_pregs != number_of_unique_pregs);
-}
-
-bool AreSameSizeAndType(const CPURegister& reg1,
-                        const CPURegister& reg2,
-                        const CPURegister& reg3,
-                        const CPURegister& reg4,
-                        const CPURegister& reg5,
-                        const CPURegister& reg6,
-                        const CPURegister& reg7,
-                        const CPURegister& reg8) {
-  VIXL_ASSERT(reg1.IsValid());
-  bool match = true;
-  match &= !reg2.IsValid() || reg2.IsSameSizeAndType(reg1);
-  match &= !reg3.IsValid() || reg3.IsSameSizeAndType(reg1);
-  match &= !reg4.IsValid() || reg4.IsSameSizeAndType(reg1);
-  match &= !reg5.IsValid() || reg5.IsSameSizeAndType(reg1);
-  match &= !reg6.IsValid() || reg6.IsSameSizeAndType(reg1);
-  match &= !reg7.IsValid() || reg7.IsSameSizeAndType(reg1);
-  match &= !reg8.IsValid() || reg8.IsSameSizeAndType(reg1);
-  return match;
-}
-
-bool AreEven(const CPURegister& reg1,
-             const CPURegister& reg2,
-             const CPURegister& reg3,
-             const CPURegister& reg4,
-             const CPURegister& reg5,
-             const CPURegister& reg6,
-             const CPURegister& reg7,
-             const CPURegister& reg8) {
-  VIXL_ASSERT(reg1.IsValid());
-  bool even = (reg1.GetCode() % 2) == 0;
-  even &= !reg2.IsValid() || ((reg2.GetCode() % 2) == 0);
-  even &= !reg3.IsValid() || ((reg3.GetCode() % 2) == 0);
-  even &= !reg4.IsValid() || ((reg4.GetCode() % 2) == 0);
-  even &= !reg5.IsValid() || ((reg5.GetCode() % 2) == 0);
-  even &= !reg6.IsValid() || ((reg6.GetCode() % 2) == 0);
-  even &= !reg7.IsValid() || ((reg7.GetCode() % 2) == 0);
-  even &= !reg8.IsValid() || ((reg8.GetCode() % 2) == 0);
-  return even;
-}
-
-bool AreConsecutive(const CPURegister& reg1,
-                    const CPURegister& reg2,
-                    const CPURegister& reg3,
-                    const CPURegister& reg4) {
-  VIXL_ASSERT(reg1.IsValid());
-
-  if (!reg2.IsValid()) {
-    return true;
-  } else if (reg2.GetCode() !=
-             ((reg1.GetCode() + 1) % (reg1.GetMaxCode() + 1))) {
-    return false;
-  }
-
-  if (!reg3.IsValid()) {
-    return true;
-  } else if (reg3.GetCode() !=
-             ((reg2.GetCode() + 1) % (reg1.GetMaxCode() + 1))) {
-    return false;
-  }
-
-  if (!reg4.IsValid()) {
-    return true;
-  } else if (reg4.GetCode() !=
-             ((reg3.GetCode() + 1) % (reg1.GetMaxCode() + 1))) {
-    return false;
-  }
-
-  return true;
-}
-
-bool AreSameFormat(const CPURegister& reg1,
-                   const CPURegister& reg2,
-                   const CPURegister& reg3,
-                   const CPURegister& reg4) {
-  VIXL_ASSERT(reg1.IsValid());
-  bool match = true;
-  match &= !reg2.IsValid() || reg2.IsSameFormat(reg1);
-  match &= !reg3.IsValid() || reg3.IsSameFormat(reg1);
-  match &= !reg4.IsValid() || reg4.IsSameFormat(reg1);
-  return match;
-}
-
-bool AreSameLaneSize(const CPURegister& reg1,
-                     const CPURegister& reg2,
-                     const CPURegister& reg3,
-                     const CPURegister& reg4) {
-  VIXL_ASSERT(reg1.IsValid());
-  bool match = true;
-  match &=
-      !reg2.IsValid() || (reg2.GetLaneSizeInBits() == reg1.GetLaneSizeInBits());
-  match &=
-      !reg3.IsValid() || (reg3.GetLaneSizeInBits() == reg1.GetLaneSizeInBits());
-  match &=
-      !reg4.IsValid() || (reg4.GetLaneSizeInBits() == reg1.GetLaneSizeInBits());
-  return match;
-}
-}
-}  // namespace vixl::aarch64
diff --git a/src/aarch64/registers-aarch64.h b/src/aarch64/registers-aarch64.h
index 911974a8..503474ec 100644
--- a/src/aarch64/registers-aarch64.h
+++ b/src/aarch64/registers-aarch64.h
@@ -126,7 +126,7 @@ class CPURegister {
   // TODO: This is temporary. Ultimately, we should move the
   // Simulator::*RegNameForCode helpers out of the simulator, and provide an
   // independent way to obtain the name of a register.
-  std::string GetArchitecturalName() const;
+  inline std::string GetArchitecturalName() const;
 
   // Return the highest valid register code for this type, to allow generic
   // loops to be written. This excludes kSPRegInternalCode, since it is not
@@ -212,13 +212,48 @@ class CPURegister {
 
   // TODO: These are stricter forms of the helpers above. We should make the
   // basic helpers strict, and remove these.
-  bool IsValidRegister() const;
-  bool IsValidVRegister() const;
-  bool IsValidFPRegister() const;
-  bool IsValidZRegister() const;
-  bool IsValidPRegister() const;
+bool IsValidRegister() const {
+  return ((code_ < kNumberOfRegisters) || (code_ == kSPRegInternalCode)) &&
+         (bank_ == kRRegisterBank) &&
+         ((size_ == kEncodedWRegSize) || (size_ == kEncodedXRegSize)) &&
+         (qualifiers_ == kNoQualifiers) && (lane_size_ == size_);
+}
+
+bool IsValidVRegister() const {
+  VIXL_STATIC_ASSERT(kEncodedBRegSize < kEncodedQRegSize);
+  return (code_ < kNumberOfVRegisters) && (bank_ == kVRegisterBank) &&
+         ((size_ >= kEncodedBRegSize) && (size_ <= kEncodedQRegSize)) &&
+         (qualifiers_ == kNoQualifiers) &&
+         (lane_size_ != kEncodedUnknownSize) && (lane_size_ <= size_);
+}
+
+bool IsValidFPRegister() const {
+  return IsValidVRegister() && IsFPRegister();
+}
+
+bool IsValidZRegister() const {
+  VIXL_STATIC_ASSERT(kEncodedBRegSize < kEncodedQRegSize);
+  // Z registers are valid with or without a lane size, so we don't need to
+  // check lane_size_.
+  return (code_ < kNumberOfZRegisters) && (bank_ == kVRegisterBank) &&
+         (size_ == kEncodedUnknownSize) && (qualifiers_ == kNoQualifiers);
+}
+
+bool IsValidPRegister() const {
+  VIXL_STATIC_ASSERT(kEncodedBRegSize < kEncodedQRegSize);
+  // P registers are valid with or without a lane size, so we don't need to
+  // check lane_size_.
+  return (code_ < kNumberOfPRegisters) && (bank_ == kPRegisterBank) &&
+         (size_ == kEncodedUnknownSize) &&
+         ((qualifiers_ == kNoQualifiers) || (qualifiers_ == kMerging) ||
+          (qualifiers_ == kZeroing));
+}
+
+  bool IsValid() const {
+    return IsValidRegister() || IsValidVRegister() || IsValidZRegister() ||
+           IsValidPRegister();
+  }
 
-  bool IsValid() const;
   bool IsValidOrNone() const { return IsNone() || IsValid(); }
 
   bool IsVector() const { return HasLaneSize() && (size_ != lane_size_); }
@@ -280,18 +315,18 @@ class CPURegister {
   // code like `cond ? reg.W() : reg.X()`, which would have indeterminate type.
 
   // Core registers, like "w0".
-  Register W() const;
-  Register X() const;
+  inline Register W() const;
+  inline Register X() const;
   // FP/NEON registers, like "b0".
-  VRegister B() const;
-  VRegister H() const;
-  VRegister S() const;
-  VRegister D() const;
-  VRegister Q() const;
-  VRegister V() const;
+  inline VRegister B() const;
+  inline VRegister H() const;
+  inline VRegister S() const;
+  inline VRegister D() const;
+  inline VRegister Q() const;
+  inline VRegister V() const;
   // SVE registers, like "z0".
-  ZRegister Z() const;
-  PRegister P() const;
+  inline ZRegister Z() const;
+  inline PRegister P() const;
 
   // Utilities for kRegister types.
 
@@ -484,7 +519,7 @@ class CPURegister {
     return DecodeSizeInBytes(encoded_size) * kBitsPerByte;
   }
 
-  static unsigned GetMaxCodeFor(CPURegister::RegisterBank bank);
+  inline static unsigned GetMaxCodeFor(CPURegister::RegisterBank bank);
 
   enum Qualifiers : uint8_t {
     kNoQualifiers = 0,
@@ -565,16 +600,19 @@ class VRegister : public CPURegister {
     VIXL_ASSERT(IsValid());
   }
 
-  VRegister V8B() const;
-  VRegister V16B() const;
-  VRegister V2H() const;
-  VRegister V4H() const;
-  VRegister V8H() const;
-  VRegister V2S() const;
-  VRegister V4S() const;
-  VRegister V1D() const;
-  VRegister V2D() const;
-  VRegister S4B() const;
+  inline VRegister V8B() const;
+  inline VRegister V16B() const;
+  inline VRegister V2H() const;
+  inline VRegister V4H() const;
+  inline VRegister V8H() const;
+  inline VRegister V2S() const;
+  inline VRegister V4S() const;
+  inline VRegister V1D() const;
+  inline VRegister V2D() const;
+
+  // Semantic type coersion for sdot and udot.
+  // TODO: Use the qualifiers_ field to distinguish this from ::S().
+  inline VRegister S4B() const;
 
   bool IsValid() const { return IsValidVRegister(); }
 
@@ -821,6 +859,52 @@ AARCH64_REGISTER_CODE_LIST(VIXL_DEFINE_REGISTERS)
 AARCH64_P_REGISTER_CODE_LIST(VIXL_DEFINE_P_REGISTERS)
 #undef VIXL_DEFINE_P_REGISTERS
 
+// Most coersions simply invoke the necessary constructor.
+#define VIXL_CPUREG_COERCION_LIST(U) \
+  U(Register, W, R)                  \
+  U(Register, X, R)                  \
+  U(VRegister, B, V)                 \
+  U(VRegister, H, V)                 \
+  U(VRegister, S, V)                 \
+  U(VRegister, D, V)                 \
+  U(VRegister, Q, V)                 \
+  U(VRegister, V, V)                 \
+  U(ZRegister, Z, V)                 \
+  U(PRegister, P, P)
+#define VIXL_DEFINE_CPUREG_COERCION(RET_TYPE, CTOR_TYPE, BANK) \
+  RET_TYPE CPURegister::CTOR_TYPE() const {                    \
+    VIXL_ASSERT(GetBank() == k##BANK##RegisterBank);           \
+    return CTOR_TYPE##Register(GetCode());                     \
+  }
+VIXL_CPUREG_COERCION_LIST(VIXL_DEFINE_CPUREG_COERCION)
+#undef VIXL_CPUREG_COERCION_LIST
+#undef VIXL_DEFINE_CPUREG_COERCION
+
+// NEON lane-format coersions always return VRegisters.
+#define VIXL_CPUREG_NEON_COERCION_LIST(V) \
+  V(8, B)                                 \
+  V(16, B)                                \
+  V(2, H)                                 \
+  V(4, H)                                 \
+  V(8, H)                                 \
+  V(2, S)                                 \
+  V(4, S)                                 \
+  V(1, D)                                 \
+  V(2, D)
+#define VIXL_DEFINE_CPUREG_NEON_COERCION(LANES, LANE_TYPE)             \
+  VRegister VRegister::V##LANES##LANE_TYPE() const {                   \
+    VIXL_ASSERT(IsVRegister());                                        \
+    return VRegister(GetCode(), LANES * k##LANE_TYPE##RegSize, LANES); \
+  }
+VIXL_CPUREG_NEON_COERCION_LIST(VIXL_DEFINE_CPUREG_NEON_COERCION)
+#undef VIXL_CPUREG_NEON_COERCION_LIST
+#undef VIXL_DEFINE_CPUREG_NEON_COERCION
+
+VRegister VRegister::S4B() const {
+  VIXL_ASSERT(IsVRegister());
+  return SRegister(GetCode());
+}
+
 // VIXL represents 'sp' with a unique code, to tell it apart from 'xzr'.
 const Register wsp = WRegister(kSPRegInternalCode);
 const Register sp = XRegister(kSPRegInternalCode);
@@ -832,8 +916,57 @@ const Register lr = x30;
 const Register xzr = x31;
 const Register wzr = w31;
 
+std::string CPURegister::GetArchitecturalName() const {
+  std::ostringstream name;
+  if (IsZRegister()) {
+    name << 'z' << GetCode();
+    if (HasLaneSize()) {
+      name << '.' << GetLaneSizeSymbol();
+    }
+  } else if (IsPRegister()) {
+    name << 'p' << GetCode();
+    if (HasLaneSize()) {
+      name << '.' << GetLaneSizeSymbol();
+    }
+    switch (qualifiers_) {
+      case kNoQualifiers:
+        break;
+      case kMerging:
+        name << "/m";
+        break;
+      case kZeroing:
+        name << "/z";
+        break;
+    }
+  } else {
+    VIXL_UNIMPLEMENTED();
+  }
+  return name.str();
+}
+
+unsigned CPURegister::GetMaxCodeFor(CPURegister::RegisterBank bank) {
+  switch (bank) {
+    case kNoRegisterBank:
+      return 0;
+    case kRRegisterBank:
+      return Register::GetMaxCode();
+    case kVRegisterBank:
+#ifdef VIXL_HAS_CONSTEXPR
+      VIXL_STATIC_ASSERT(VRegister::GetMaxCode() == ZRegister::GetMaxCode());
+#else
+      VIXL_ASSERT(VRegister::GetMaxCode() == ZRegister::GetMaxCode());
+#endif
+      return VRegister::GetMaxCode();
+    case kPRegisterBank:
+      return PRegister::GetMaxCode();
+  }
+  VIXL_UNREACHABLE();
+  return 0;
+}
+
 // AreAliased returns true if any of the named registers overlap. Arguments
 // set to NoReg are ignored. The system stack pointer may be specified.
+inline
 bool AreAliased(const CPURegister& reg1,
                 const CPURegister& reg2,
                 const CPURegister& reg3 = NoReg,
@@ -841,12 +974,55 @@ bool AreAliased(const CPURegister& reg1,
                 const CPURegister& reg5 = NoReg,
                 const CPURegister& reg6 = NoReg,
                 const CPURegister& reg7 = NoReg,
-                const CPURegister& reg8 = NoReg);
+                const CPURegister& reg8 = NoReg) {
+  int number_of_valid_regs = 0;
+  int number_of_valid_vregs = 0;
+  int number_of_valid_pregs = 0;
+
+  RegList unique_regs = 0;
+  RegList unique_vregs = 0;
+  RegList unique_pregs = 0;
+
+  const CPURegister regs[] = {reg1, reg2, reg3, reg4, reg5, reg6, reg7, reg8};
+
+  for (size_t i = 0; i < ArrayLength(regs); i++) {
+    switch (regs[i].GetBank()) {
+      case CPURegister::kRRegisterBank:
+        number_of_valid_regs++;
+        unique_regs |= regs[i].GetBit();
+        break;
+      case CPURegister::kVRegisterBank:
+        number_of_valid_vregs++;
+        unique_vregs |= regs[i].GetBit();
+        break;
+      case CPURegister::kPRegisterBank:
+        number_of_valid_pregs++;
+        unique_pregs |= regs[i].GetBit();
+        break;
+      case CPURegister::kNoRegisterBank:
+        VIXL_ASSERT(regs[i].IsNone());
+        break;
+    }
+  }
+
+  int number_of_unique_regs = CountSetBits(unique_regs);
+  int number_of_unique_vregs = CountSetBits(unique_vregs);
+  int number_of_unique_pregs = CountSetBits(unique_pregs);
+
+  VIXL_ASSERT(number_of_valid_regs >= number_of_unique_regs);
+  VIXL_ASSERT(number_of_valid_vregs >= number_of_unique_vregs);
+  VIXL_ASSERT(number_of_valid_pregs >= number_of_unique_pregs);
+
+  return (number_of_valid_regs != number_of_unique_regs) ||
+         (number_of_valid_vregs != number_of_unique_vregs) ||
+         (number_of_valid_pregs != number_of_unique_pregs);
+}
 
 // AreSameSizeAndType returns true if all of the specified registers have the
 // same size, and are of the same type. The system stack pointer may be
 // specified. Arguments set to NoReg are ignored, as are any subsequent
 // arguments. At least one argument (reg1) must be valid (not NoCPUReg).
+inline
 bool AreSameSizeAndType(const CPURegister& reg1,
                         const CPURegister& reg2,
                         const CPURegister& reg3 = NoCPUReg,
@@ -854,11 +1030,23 @@ bool AreSameSizeAndType(const CPURegister& reg1,
                         const CPURegister& reg5 = NoCPUReg,
                         const CPURegister& reg6 = NoCPUReg,
                         const CPURegister& reg7 = NoCPUReg,
-                        const CPURegister& reg8 = NoCPUReg);
+                        const CPURegister& reg8 = NoCPUReg) {
+  VIXL_ASSERT(reg1.IsValid());
+  bool match = true;
+  match &= !reg2.IsValid() || reg2.IsSameSizeAndType(reg1);
+  match &= !reg3.IsValid() || reg3.IsSameSizeAndType(reg1);
+  match &= !reg4.IsValid() || reg4.IsSameSizeAndType(reg1);
+  match &= !reg5.IsValid() || reg5.IsSameSizeAndType(reg1);
+  match &= !reg6.IsValid() || reg6.IsSameSizeAndType(reg1);
+  match &= !reg7.IsValid() || reg7.IsSameSizeAndType(reg1);
+  match &= !reg8.IsValid() || reg8.IsSameSizeAndType(reg1);
+  return match;
+}
 
 // AreEven returns true if all of the specified registers have even register
 // indices. Arguments set to NoReg are ignored, as are any subsequent
 // arguments. At least one argument (reg1) must be valid (not NoCPUReg).
+inline
 bool AreEven(const CPURegister& reg1,
              const CPURegister& reg2,
              const CPURegister& reg3 = NoReg,
@@ -866,34 +1054,91 @@ bool AreEven(const CPURegister& reg1,
              const CPURegister& reg5 = NoReg,
              const CPURegister& reg6 = NoReg,
              const CPURegister& reg7 = NoReg,
-             const CPURegister& reg8 = NoReg);
+             const CPURegister& reg8 = NoReg) {
+  VIXL_ASSERT(reg1.IsValid());
+  bool even = (reg1.GetCode() % 2) == 0;
+  even &= !reg2.IsValid() || ((reg2.GetCode() % 2) == 0);
+  even &= !reg3.IsValid() || ((reg3.GetCode() % 2) == 0);
+  even &= !reg4.IsValid() || ((reg4.GetCode() % 2) == 0);
+  even &= !reg5.IsValid() || ((reg5.GetCode() % 2) == 0);
+  even &= !reg6.IsValid() || ((reg6.GetCode() % 2) == 0);
+  even &= !reg7.IsValid() || ((reg7.GetCode() % 2) == 0);
+  even &= !reg8.IsValid() || ((reg8.GetCode() % 2) == 0);
+  return even;
+}
 
 // AreConsecutive returns true if all of the specified registers are
 // consecutive in the register file. Arguments set to NoReg are ignored, as are
 // any subsequent arguments. At least one argument (reg1) must be valid
 // (not NoCPUReg).
+inline
 bool AreConsecutive(const CPURegister& reg1,
                     const CPURegister& reg2,
                     const CPURegister& reg3 = NoCPUReg,
-                    const CPURegister& reg4 = NoCPUReg);
+                    const CPURegister& reg4 = NoCPUReg) {
+  VIXL_ASSERT(reg1.IsValid());
+
+  if (!reg2.IsValid()) {
+    return true;
+  } else if (reg2.GetCode() !=
+             ((reg1.GetCode() + 1) % (reg1.GetMaxCode() + 1))) {
+    return false;
+  }
+
+  if (!reg3.IsValid()) {
+    return true;
+  } else if (reg3.GetCode() !=
+             ((reg2.GetCode() + 1) % (reg1.GetMaxCode() + 1))) {
+    return false;
+  }
+
+  if (!reg4.IsValid()) {
+    return true;
+  } else if (reg4.GetCode() !=
+             ((reg3.GetCode() + 1) % (reg1.GetMaxCode() + 1))) {
+    return false;
+  }
+
+  return true;
+}
 
 // AreSameFormat returns true if all of the specified registers have the same
 // vector format. Arguments set to NoReg are ignored, as are any subsequent
 // arguments. At least one argument (reg1) must be valid (not NoVReg).
+inline
 bool AreSameFormat(const CPURegister& reg1,
                    const CPURegister& reg2,
                    const CPURegister& reg3 = NoCPUReg,
-                   const CPURegister& reg4 = NoCPUReg);
+                   const CPURegister& reg4 = NoCPUReg) {
+  VIXL_ASSERT(reg1.IsValid());
+  bool match = true;
+  match &= !reg2.IsValid() || reg2.IsSameFormat(reg1);
+  match &= !reg3.IsValid() || reg3.IsSameFormat(reg1);
+  match &= !reg4.IsValid() || reg4.IsSameFormat(reg1);
+  return match;
+}
 
 // AreSameLaneSize returns true if all of the specified registers have the same
 // element lane size, B, H, S or D. It doesn't compare the type of registers.
 // Arguments set to NoReg are ignored, as are any subsequent arguments.
 // At least one argument (reg1) must be valid (not NoVReg).
 // TODO: Remove this, and replace its uses with AreSameFormat.
+inline
 bool AreSameLaneSize(const CPURegister& reg1,
                      const CPURegister& reg2,
                      const CPURegister& reg3 = NoCPUReg,
-                     const CPURegister& reg4 = NoCPUReg);
+                     const CPURegister& reg4 = NoCPUReg) {
+  VIXL_ASSERT(reg1.IsValid());
+  bool match = true;
+  match &=
+      !reg2.IsValid() || (reg2.GetLaneSizeInBits() == reg1.GetLaneSizeInBits());
+  match &=
+      !reg3.IsValid() || (reg3.GetLaneSizeInBits() == reg1.GetLaneSizeInBits());
+  match &=
+      !reg4.IsValid() || (reg4.GetLaneSizeInBits() == reg1.GetLaneSizeInBits());
+  return match;
+}
+
 }
 }  // namespace vixl::aarch64
 
diff --git a/src/assembler-base-vixl.h b/src/assembler-base-vixl.h
index ee54dcbc..60bcf51c 100644
--- a/src/assembler-base-vixl.h
+++ b/src/assembler-base-vixl.h
@@ -37,14 +37,22 @@ namespace internal {
 
 class AssemblerBase {
  public:
-  AssemblerBase() : allow_assembler_(false) {}
+  AssemblerBase() : allow_assembler_(true) {}
+#ifdef PANDA_BUILD
+  AssemblerBase(size_t capacity) = delete;
+#else
   explicit AssemblerBase(size_t capacity)
       : buffer_(capacity), allow_assembler_(false) {}
+#endif
   AssemblerBase(byte* buffer, size_t capacity)
-      : buffer_(buffer, capacity), allow_assembler_(false) {}
+      : buffer_(buffer, capacity), allow_assembler_(true) {}
 
   virtual ~AssemblerBase() {}
 
+  bool IsValid() const {
+    return buffer_.IsValid();
+  }
+
   // Finalize a code buffer of generated instructions. This function must be
   // called before executing or copying code from the buffer.
   void FinalizeCode() { GetBuffer()->SetClean(); }
diff --git a/src/code-buffer-vixl.cc b/src/code-buffer-vixl.cc
index 19a3c6c8..c2f40d32 100644
--- a/src/code-buffer-vixl.cc
+++ b/src/code-buffer-vixl.cc
@@ -120,6 +120,13 @@ void CodeBuffer::SetWritable() {
 #endif
 }
 
+// For some reason OHOS toolchain doesn't have this function
+#ifdef PANDA_TARGET_MOBILE
+char* stpcpy (char *dst, const char *src) {
+    const size_t len = strlen (src);
+    return (char *) memcpy (dst, src, len + 1) + len;
+}
+#endif
 
 void CodeBuffer::EmitString(const char* string) {
   VIXL_ASSERT(HasSpaceFor(strlen(string) + 1));
diff --git a/src/code-generation-scopes-vixl.h b/src/code-generation-scopes-vixl.h
index b7ea2d92..c56759e6 100644
--- a/src/code-generation-scopes-vixl.h
+++ b/src/code-generation-scopes-vixl.h
@@ -235,7 +235,7 @@ class EmissionCheckScope : public CodeBufferCheckScope {
     Open(masm, size, size_policy, pool_policy);
   }
 
-  MacroAssemblerInterface* masm_;
+  MacroAssemblerInterface* masm_{nullptr};
   PoolPolicy pool_policy_;
 };
 
diff --git a/src/pool-manager.h b/src/pool-manager.h
index b60d8c43..0d4921c5 100644
--- a/src/pool-manager.h
+++ b/src/pool-manager.h
@@ -206,13 +206,17 @@ class LocationBase {
   // we need to keep track of the location in order to resolve the references
   // to the object. Reusing the location_ field for this is convenient.
   void SetLocation(internal::AssemblerBase* assembler, T location) {
+#ifndef PANDA_BUILD
     VIXL_ASSERT(!is_bound_);
+#endif
     location_ = location;
     ResolveReferences(assembler);
   }
 
   void MarkBound() {
+#ifndef PANDA_BUILD
     VIXL_ASSERT(!is_bound_);
+#endif
     is_bound_ = true;
   }
 
-- 
2.17.1

